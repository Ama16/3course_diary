{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, drop_invariant=False):\n",
    "        self.cols = cols\n",
    "        self.drop_invariant = drop_invariant\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.drop_invariant:\n",
    "            self.drop = []\n",
    "            for i in self.cols:\n",
    "                if len(X[i].unique()) == 1:\n",
    "                    self.drop.append(i)\n",
    "            for i in self.drop:\n",
    "                self.cols.remove(i)\n",
    "        self.le = []\n",
    "        for i in self.cols:\n",
    "            self.le.append(preprocessing.LabelEncoder().fit(X[i]))\n",
    "        return self   \n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.drop_invariant:\n",
    "            X = X.drop(self.drop, axis=1)\n",
    "        \n",
    "        for i, j in zip(self.cols, self.le):\n",
    "            X.loc[:, i+'_le'] = j.transform(X[i])\n",
    "        X = X.drop(self.cols, axis=1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return [(i+'_le') for i in self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, drop_invariant=False, handle_unknown='value', handle_missing='value'):\n",
    "        self.cols = cols\n",
    "        self.drop_invariant = drop_invariant\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.handle_missing = handle_missing\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.drop_invariant:\n",
    "            self.drop = []\n",
    "            for i in self.cols:\n",
    "                if len(X[i].unique()) == 1:\n",
    "                    self.drop.append(i)\n",
    "            for i in self.drop:\n",
    "                self.cols.remove(i)\n",
    "        self.maps = []\n",
    "        for i in self.cols:\n",
    "            self.maps.append(X.groupby(i).size() / len(X))\n",
    "        return self   \n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.drop_invariant:\n",
    "            X = X.drop(self.drop, axis=1)\n",
    "        \n",
    "        if self.handle_missing == 'error':\n",
    "            if X[self.cols].isnull().any().any():\n",
    "                raise ValueError('Columns to be encoded can not contain null')\n",
    "        \n",
    "        for i, j in zip(self.cols, self.maps):\n",
    "            X.loc[:, i+'_freq'] = X[i].map(j)\n",
    "        X = X.drop(self.cols, axis=1)\n",
    "        \n",
    "        if self.handle_unknown == 'error':\n",
    "            if X[[(i+'_freq') for i in self.cols]].isnull().any().any():\n",
    "                raise ValueError('Columns contain unexpected value')\n",
    "        \n",
    "        X[[(i+'_freq') for i in self.cols]] = X[[(i+'_freq') for i in self.cols]].fillna(0)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return [(i+'_freq') for i in self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col, method=None, unknown=None, min_samples = 0, smoothing = 0):\n",
    "        self.col = col\n",
    "        self.method = method\n",
    "        \n",
    "        if self.method == None:\n",
    "            self.method = np.mean\n",
    "        self.unknown = unknown\n",
    "        self.smoothing = float(smoothing)\n",
    "        self.min_samples = min_samples\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        \"\"\"\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : Series\n",
    "            Колонка с обучающими значениями\n",
    "        y : Series\n",
    "            Колонка таргета\n",
    "        \"\"\"\n",
    "        col = X[self.col].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        \n",
    "        prior = y.mean()\n",
    "        name = self.method.__name__\n",
    "        stats = y.groupby(col).agg(['count', self.method])\n",
    "        \n",
    "        if self.smoothing > 0:\n",
    "            smoove = 1 / (1 + np.exp(-(stats['count'] - self.min_samples) / self.smoothing))\n",
    "            smoothing = prior * (1 - smoove) + stats[name] * smoove\n",
    "            smoothing[stats['count'] < self.min_samples] = prior #если меньше min_samples, присваиваем общее среднее\n",
    "        \n",
    "        if self.smoothing > 0:\n",
    "            self.d = smoothing\n",
    "            return self\n",
    "        \n",
    "        self.d = dict(zip(np.unique(col), np.zeros(len(np.unique(col)))))\n",
    "        for i in np.unique(col):\n",
    "            if stats['count'][i] < self.min_samples:\n",
    "                self.d[i] = prior\n",
    "            else:\n",
    "                self.d[i] = stats[name][i]\n",
    "        return self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : Series\n",
    "            Колонка с преобразуемыми значениями\n",
    "        \"\"\"\n",
    "        col = X[self.col]\n",
    "        answer = np.empty(len(col))\n",
    "        for k, i in enumerate(X.index):\n",
    "            if col[i] in self.d.keys():\n",
    "                answer[k] = self.d[col[i]]\n",
    "            else:\n",
    "                if self.unknown == None:\n",
    "                    answer[k] = np.mean(list(d.values()))\n",
    "                    #raise Exception(\"Unexpected value\")\n",
    "                else:\n",
    "                    answer[k] = self.unknown\n",
    "        return pd.Series(answer, index=col.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "class MyTransformerWithTargetMixin:\n",
    "    def fit_transform(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise TypeError('fit_transform() missing argument: ''y''')\n",
    "        return self.fit(X, y).transform(X, y)\n",
    "\n",
    "class JamesSteinEncoder(BaseEstimator, MyTransformerWithTargetMixin):\n",
    "    def __init__(self, cols=None, random_state=None, randomized=False, sigma=0.05):\n",
    "        self.cols = cols\n",
    "        self.random_state = random_state\n",
    "        self.randomized = randomized\n",
    "        self.sigma = sigma\n",
    "        self.mapping = {}\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        col = X[self.cols].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True).astype('float')\n",
    "        prior = y.mean()\n",
    "        global_count = len(y)\n",
    "        global_var = y.var()\n",
    "        \n",
    "        for name_col in self.cols:\n",
    "            stats = y.groupby(col[name_col]).agg(['mean', 'var'])\n",
    "\n",
    "            i_var = stats['var'].fillna(0) \n",
    "\n",
    "            smoothing = i_var / (global_var + i_var) \n",
    "            self.mapping[name_col] = (1 - smoothing)*(stats['mean']) + smoothing*prior\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_now = X.copy()\n",
    "        for col in self.cols:\n",
    "            X_now[col] = X_now[col].map(self.mapping[col])\n",
    "            \n",
    "            X_now[col].fillna(np.nanmean(X_now[col]), inplace=True)\n",
    "\n",
    "            if self.randomized and y is not None:\n",
    "                random_state_generator = check_random_state(self.random_state)\n",
    "                X_now[col] = (X_now[col] * random_state_generator.normal(1., self.sigma, X_now[col].shape[0]))\n",
    "\n",
    "        return X_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WoEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col=None, unknown=None):\n",
    "        self.col = col\n",
    "        self.unknown = unknown\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        col = X[self.col].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        data = pd.DataFrame(pd.concat([col, y], axis=1))\n",
    "        name = data.columns[1]\n",
    "        tmp = pd.DataFrame(data.groupby(col)[name].count())[name]\n",
    "        data = pd.DataFrame(data.groupby(col)[name].sum())\n",
    "        data['not_target'] = tmp - data[name]\n",
    "        data['answer'] = np.log((data[name] + 0.5) / (data['not_target'] + 0.5))\n",
    "        self.d = dict(data['answer'])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        col = X[self.col]\n",
    "        answer = np.empty(len(col))\n",
    "        for k, i in enumerate(X.index):\n",
    "            if col[i] in self.d.keys():\n",
    "                answer[k] = self.d[col[i]]\n",
    "            else:\n",
    "                if self.unknown == None:\n",
    "                    raise Exception(\"Unexpected value\")\n",
    "                else:\n",
    "                    answer[k] = self.unknown\n",
    "        return pd.Series(answer, index=col.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('onetwotrip_challenge_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['goal1']\n",
    "X.drop(columns=['goal1', 'orderid', 'userid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Stein encoding:\n",
      "0.6786413939517448\n",
      "[0.6738166881660616, 0.6641634927096702, 0.66962179999932, 0.6942065426267652, 0.6913984462569072]\n",
      "\n",
      "Label encoding:\n",
      "0.6993999069361964\n",
      "[0.6959979881278985, 0.7024920909114327, 0.6910698362767196, 0.705868832139849, 0.701570787225082]\n",
      "\n",
      "Frequency encoding:\n",
      "0.7060655188000573\n",
      "[0.699596874794978, 0.7079370906583015, 0.6984017723454279, 0.7129159180228162, 0.7114759381787632]\n",
      "\n",
      "Target encoding, smoothing=0:\n",
      "0.699512462416054\n",
      "[0.6916021723321268, 0.699960510329333, 0.6910938160962748, 0.708365174068412, 0.706540639254124]\n",
      "\n",
      "Target encoding, smoothing=1:\n",
      "0.6997025437296716\n",
      "[0.6915223870149815, 0.6998284120863141, 0.6913211994232216, 0.7088076294059825, 0.7070330907178586]\n",
      "\n",
      "Target encoding, smoothing=2:\n",
      "0.7001788110861481\n",
      "[0.6918883657010111, 0.6997209428334369, 0.6913164338135126, 0.7098590558567649, 0.7081092572260148]\n",
      "\n",
      "WoE encoding:\n",
      "0.6770383188716746\n",
      "[0.6686377750066762, 0.6595686393000513, 0.6710196717083781, 0.6934268716197328, 0.6925386367235351]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    js = JamesSteinEncoder(cols=cols, randomized=False, sigma=0.02)\n",
    "    X_train = js.fit_transform(X_train, y_train)\n",
    "    X_test = js.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"James Stein encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "le = LabelEncoder(cols)\n",
    "x = le.fit_transform(X)\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = x.iloc[train_index].copy(), x.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Label encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "fe = FrequencyEncoder(cols)\n",
    "x = fe.fit_transform(X.copy())\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = x.iloc[train_index].copy(), x.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Frequency encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        te = TargetEncoder(i, smoothing = 0, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=0:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        te = TargetEncoder(i, smoothing = 1, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=1:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        te = TargetEncoder(i, smoothing = 2, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=2:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        woe = WoEEncoder(i, unknown=-0.7)\n",
    "        X_train[i] = woe.fit_transform(X_train, y_train)\n",
    "        X_test[i] = woe.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"WoE encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
