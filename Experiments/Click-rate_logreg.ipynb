{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, drop_invariant=False):\n",
    "        self.cols = cols\n",
    "        self.drop_invariant = drop_invariant\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.drop_invariant:\n",
    "            self.drop = []\n",
    "            for i in self.cols:\n",
    "                if len(X[i].unique()) == 1:\n",
    "                    self.drop.append(i)\n",
    "            for i in self.drop:\n",
    "                self.cols.remove(i)\n",
    "        self.le = []\n",
    "        for i in self.cols:\n",
    "            self.le.append(preprocessing.LabelEncoder().fit(X[i]))\n",
    "        return self   \n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.drop_invariant:\n",
    "            X = X.drop(self.drop, axis=1)\n",
    "        \n",
    "        for i, j in zip(self.cols, self.le):\n",
    "            X.loc[:, i+'_le'] = j.transform(X[i])\n",
    "        X = X.drop(self.cols, axis=1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return [(i+'_le') for i in self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col, method=None, unknown=None, min_samples = 0, smoothing = 0):\n",
    "        self.col = col\n",
    "        self.method = method\n",
    "        \n",
    "        if self.method == None:\n",
    "            self.method = np.mean\n",
    "        self.unknown = unknown\n",
    "        self.smoothing = float(smoothing)\n",
    "        self.min_samples = min_samples\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        \"\"\"\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : Series\n",
    "            Колонка с обучающими значениями\n",
    "        y : Series\n",
    "            Колонка таргета\n",
    "        \"\"\"\n",
    "        col = X[self.col].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        \n",
    "        prior = y.mean()\n",
    "        name = self.method.__name__\n",
    "        stats = y.groupby(col).agg(['count', self.method])\n",
    "        \n",
    "        if self.smoothing > 0:\n",
    "            smoove = 1 / (1 + np.exp(-(stats['count'] - self.min_samples) / self.smoothing))\n",
    "            smoothing = prior * (1 - smoove) + stats[name] * smoove\n",
    "            smoothing[stats['count'] < self.min_samples] = prior #если меньше min_samples, присваиваем общее среднее\n",
    "        \n",
    "        if self.smoothing > 0:\n",
    "            self.d = smoothing\n",
    "            return self\n",
    "        \n",
    "        self.d = dict(zip(np.unique(col), np.zeros(len(np.unique(col)))))\n",
    "        for i in np.unique(col):\n",
    "            if stats['count'][i] < self.min_samples:\n",
    "                self.d[i] = prior\n",
    "            else:\n",
    "                self.d[i] = stats[name][i]\n",
    "        return self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : Series\n",
    "            Колонка с преобразуемыми значениями\n",
    "        \"\"\"\n",
    "        col = X[self.col]\n",
    "        answer = np.empty(len(col))\n",
    "        for k, i in enumerate(X.index):\n",
    "            if col[i] in self.d.keys():\n",
    "                answer[k] = self.d[col[i]]\n",
    "            else:\n",
    "                if self.unknown == None:\n",
    "                    answer[k] = np.mean(list(d.values()))\n",
    "                    #raise Exception(\"Unexpected value\")\n",
    "                else:\n",
    "                    answer[k] = self.unknown\n",
    "        return pd.Series(answer, index=col.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, drop_invariant=False, handle_unknown='value', handle_missing='value'):\n",
    "        self.cols = cols\n",
    "        self.drop_invariant = drop_invariant\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.handle_missing = handle_missing\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.drop_invariant:\n",
    "            self.drop = []\n",
    "            for i in self.cols:\n",
    "                if len(X[i].unique()) == 1:\n",
    "                    self.drop.append(i)\n",
    "            for i in self.drop:\n",
    "                self.cols.remove(i)\n",
    "        self.maps = []\n",
    "        for i in self.cols:\n",
    "            self.maps.append(X.groupby(i).size() / len(X))\n",
    "        return self   \n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.drop_invariant:\n",
    "            X = X.drop(self.drop, axis=1)\n",
    "        \n",
    "        if self.handle_missing == 'error':\n",
    "            if X[self.cols].isnull().any().any():\n",
    "                raise ValueError('Columns to be encoded can not contain null')\n",
    "        \n",
    "        for i, j in zip(self.cols, self.maps):\n",
    "            X.loc[:, i+'_freq'] = X[i].map(j)\n",
    "        X = X.drop(self.cols, axis=1)\n",
    "        \n",
    "        if self.handle_unknown == 'error':\n",
    "            if X[[(i+'_freq') for i in self.cols]].isnull().any().any():\n",
    "                raise ValueError('Columns contain unexpected value')\n",
    "        \n",
    "        X[[(i+'_freq') for i in self.cols]] = X[[(i+'_freq') for i in self.cols]].fillna(0)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return [(i+'_freq') for i in self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WoEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col=None, unknown=None):\n",
    "        self.col = col\n",
    "        self.unknown = unknown\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        col = X[self.col].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        data = pd.DataFrame(pd.concat([col, y], axis=1))\n",
    "        name = data.columns[1]\n",
    "        tmp = pd.DataFrame(data.groupby(col)[name].count())[name]\n",
    "        data = pd.DataFrame(data.groupby(col)[name].sum())\n",
    "        data['not_target'] = tmp - data[name]\n",
    "        data['answer'] = np.log((data[name] + 0.5) / (data['not_target'] + 0.5))\n",
    "        self.d = dict(data['answer'])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        col = X[self.col]\n",
    "        answer = np.empty(len(col))\n",
    "        for k, i in enumerate(X.index):\n",
    "            if col[i] in self.d.keys():\n",
    "                answer[k] = self.d[col[i]]\n",
    "            else:\n",
    "                if self.unknown == None:\n",
    "                    raise Exception(\"Unexpected value\")\n",
    "                else:\n",
    "                    answer[k] = self.unknown\n",
    "        return pd.Series(answer, index=col.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "class MyTransformerWithTargetMixin:\n",
    "    def fit_transform(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise TypeError('fit_transform() missing argument: ''y''')\n",
    "        return self.fit(X, y).transform(X, y)\n",
    "\n",
    "class JamesSteinEncoder(BaseEstimator, MyTransformerWithTargetMixin):\n",
    "    def __init__(self, cols=None, random_state=None, randomized=False, sigma=0.05):\n",
    "        self.cols = cols\n",
    "        self.random_state = random_state\n",
    "        self.randomized = randomized\n",
    "        self.sigma = sigma\n",
    "        self.mapping = {}\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        col = X[self.cols].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True).astype('float')\n",
    "        prior = y.mean()\n",
    "        global_count = len(y)\n",
    "        global_var = y.var()\n",
    "        \n",
    "        for name_col in self.cols:\n",
    "            stats = y.groupby(col[name_col]).agg(['mean', 'var'])\n",
    "\n",
    "            i_var = stats['var'].fillna(0) \n",
    "\n",
    "            smoothing = i_var / (global_var + i_var) \n",
    "            self.mapping[name_col] = (1 - smoothing)*(stats['mean']) + smoothing*prior\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_now = X.copy()\n",
    "        for col in self.cols:\n",
    "            X_now[col] = X_now[col].map(self.mapping[col])\n",
    "            \n",
    "            X_now[col].fillna(np.nanmean(X_now[col]), inplace=True)\n",
    "\n",
    "            if self.randomized and y is not None:\n",
    "                random_state_generator = check_random_state(self.random_state)\n",
    "                X_now[col] = (X_now[col] * random_state_generator.normal(1., self.sigma, X_now[col].shape[0]))\n",
    "\n",
    "        return X_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/Users/ama/Desktop/avazu-ctr-prediction/train', nrows=150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['click']\n",
    "X.drop(columns=['id', 'click'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Stein encoding:\n",
      "0.7175811832012471\n",
      "[0.7195900896095584, 0.7206760545905706, 0.7157457313175848, 0.7132912719456512, 0.7186027685428704]\n",
      "\n",
      "Label encoding:\n",
      "0.6403655251958359\n",
      "[0.6302045674995456, 0.6435628566997519, 0.6405379234249822, 0.6451310903915723, 0.6423911879633275]\n",
      "\n",
      "Frequency encoding:\n",
      "0.6673855871824989\n",
      "[0.6652753569948695, 0.6692129419975186, 0.665428157305733, 0.6675532525817769, 0.6694582270325962]\n",
      "\n",
      "Target encoding, smoothing=0:\n",
      "0.7338848966576875\n",
      "[0.7352402813398862, 0.7386787026985111, 0.730797167281402, 0.7297057986467526, 0.7350025333218855]\n",
      "\n",
      "Target encoding, smoothing=1:\n",
      "0.7356152167889991\n",
      "[0.7371162260394195, 0.7403092160359801, 0.7325975564560249, 0.731532361665508, 0.7365207237480635]\n",
      "\n",
      "Target encoding, smoothing=2:\n",
      "0.7354399009102892\n",
      "[0.7369071103695505, 0.7401716384925559, 0.7324404364096185, 0.731598872705097, 0.7360814465746244]\n",
      "\n",
      "WoE encoding:\n",
      "0.7381541669928152\n",
      "[0.7391227054959937, 0.7440584057071961, 0.7336507180778211, 0.7338322767359071, 0.7401067289471579]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    js = JamesSteinEncoder(cols=X_train.columns, randomized=False, sigma=0.02)\n",
    "    X_train = js.fit_transform(X_train, y_train)\n",
    "    X_test = js.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"James Stein encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "le = LabelEncoder(X.columns)\n",
    "x = le.fit_transform(X)\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = x.iloc[train_index].copy(), x.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Label encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "fe = FrequencyEncoder(X.columns)\n",
    "x = fe.fit_transform(X.copy())\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = x.iloc[train_index].copy(), x.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Frequency encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in X_test.columns:\n",
    "        te = TargetEncoder(i, smoothing = 0, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=0:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in X_test.columns:\n",
    "        te = TargetEncoder(i, smoothing = 1, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=1:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in X_test.columns:\n",
    "        te = TargetEncoder(i, smoothing = 2, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=2:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in X.columns:\n",
    "        woe = WoEEncoder(i, unknown=-0.7)\n",
    "        X_train[i] = woe.fit_transform(X_train, y_train)\n",
    "        X_test[i] = woe.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"WoE encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
