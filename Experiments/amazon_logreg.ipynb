{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import preprocessing\n",
    "\n",
    "class LabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, drop_invariant=False):\n",
    "        self.cols = cols\n",
    "        self.drop_invariant = drop_invariant\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.drop_invariant:\n",
    "            self.drop = []\n",
    "            for i in self.cols:\n",
    "                if len(X[i].unique()) == 1:\n",
    "                    self.drop.append(i)\n",
    "            for i in self.drop:\n",
    "                self.cols.remove(i)\n",
    "        self.le = []\n",
    "        for i in self.cols:\n",
    "            self.le.append(preprocessing.LabelEncoder().fit(X[i]))\n",
    "        return self   \n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.drop_invariant:\n",
    "            X = X.drop(self.drop, axis=1)\n",
    "        \n",
    "        for i, j in zip(self.cols, self.le):\n",
    "            X.loc[:, i+'_le'] = j.transform(X[i])\n",
    "        X = X.drop(self.cols, axis=1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return [(i+'_le') for i in self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None, drop_invariant=False, handle_unknown='value', handle_missing='value'):\n",
    "        self.cols = cols\n",
    "        self.drop_invariant = drop_invariant\n",
    "        self.handle_unknown = handle_unknown\n",
    "        self.handle_missing = handle_missing\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        if self.drop_invariant:\n",
    "            self.drop = []\n",
    "            for i in self.cols:\n",
    "                if len(X[i].unique()) == 1:\n",
    "                    self.drop.append(i)\n",
    "            for i in self.drop:\n",
    "                self.cols.remove(i)\n",
    "        self.maps = []\n",
    "        for i in self.cols:\n",
    "            self.maps.append(X.groupby(i).size() / len(X))\n",
    "        return self   \n",
    "        \n",
    "    def transform(self, X):\n",
    "        if self.drop_invariant:\n",
    "            X = X.drop(self.drop, axis=1)\n",
    "        \n",
    "        if self.handle_missing == 'error':\n",
    "            if X[self.cols].isnull().any().any():\n",
    "                raise ValueError('Columns to be encoded can not contain null')\n",
    "        \n",
    "        for i, j in zip(self.cols, self.maps):\n",
    "            X.loc[:, i+'_freq'] = X[i].map(j)\n",
    "        X = X.drop(self.cols, axis=1)\n",
    "        \n",
    "        if self.handle_unknown == 'error':\n",
    "            if X[[(i+'_freq') for i in self.cols]].isnull().any().any():\n",
    "                raise ValueError('Columns contain unexpected value')\n",
    "        \n",
    "        X[[(i+'_freq') for i in self.cols]] = X[[(i+'_freq') for i in self.cols]].fillna(0)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        return [(i+'_freq') for i in self.cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, col, method=None, unknown=None, min_samples = 0, smoothing = 0):\n",
    "        self.col = col\n",
    "        self.method = method\n",
    "        \n",
    "        if self.method == None:\n",
    "            self.method = np.mean\n",
    "        self.unknown = unknown\n",
    "        self.smoothing = float(smoothing)\n",
    "        self.min_samples = min_samples\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        \"\"\"\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : Series\n",
    "            Колонка с обучающими значениями\n",
    "        y : Series\n",
    "            Колонка таргета\n",
    "        \"\"\"\n",
    "        col = X[self.col].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        \n",
    "        prior = y.mean()\n",
    "        name = self.method.__name__\n",
    "        stats = y.groupby(col).agg(['count', self.method])\n",
    "        \n",
    "        if self.smoothing > 0:\n",
    "            smoove = 1 / (1 + np.exp(-(stats['count'] - self.min_samples) / self.smoothing))\n",
    "            smoothing = prior * (1 - smoove) + stats[name] * smoove\n",
    "            smoothing[stats['count'] < self.min_samples] = prior #если меньше min_samples, присваиваем общее среднее\n",
    "        \n",
    "        if self.smoothing > 0:\n",
    "            self.d = smoothing\n",
    "            return self\n",
    "        \n",
    "        self.d = dict(zip(np.unique(col), np.zeros(len(np.unique(col)))))\n",
    "        for i in np.unique(col):\n",
    "            if stats['count'][i] < self.min_samples:\n",
    "                self.d[i] = prior\n",
    "            else:\n",
    "                self.d[i] = stats[name][i]\n",
    "        return self\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Параметры\n",
    "        ----------\n",
    "        X : Series\n",
    "            Колонка с преобразуемыми значениями\n",
    "        \"\"\"\n",
    "        col = X[self.col]\n",
    "        answer = np.empty(len(col))\n",
    "        for k, i in enumerate(X.index):\n",
    "            if col[i] in self.d.keys():\n",
    "                answer[k] = self.d[col[i]]\n",
    "            else:\n",
    "                if self.unknown == None:\n",
    "                    answer[k] = np.mean(list(d.values()))\n",
    "                    #raise Exception(\"Unexpected value\")\n",
    "                else:\n",
    "                    answer[k] = self.unknown\n",
    "        return pd.Series(answer, index=col.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "\n",
    "class MyTransformerWithTargetMixin:\n",
    "    def fit_transform(self, X, y=None):\n",
    "        if y is None:\n",
    "            raise TypeError('fit_transform() missing argument: ''y''')\n",
    "        return self.fit(X, y).transform(X, y)\n",
    "\n",
    "class JamesSteinEncoder(BaseEstimator, MyTransformerWithTargetMixin):\n",
    "    def __init__(self, cols=None, random_state=None, randomized=False, sigma=0.05):\n",
    "        self.cols = cols\n",
    "        self.random_state = random_state\n",
    "        self.randomized = randomized\n",
    "        self.sigma = sigma\n",
    "        self.mapping = {}\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        col = X[self.cols].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True).astype('float')\n",
    "        prior = y.mean()\n",
    "        global_count = len(y)\n",
    "        global_var = y.var()\n",
    "        \n",
    "        for name_col in self.cols:\n",
    "            stats = y.groupby(col[name_col]).agg(['mean', 'var'])\n",
    "\n",
    "            i_var = stats['var'].fillna(0) \n",
    "\n",
    "            smoothing = i_var / (global_var + i_var) \n",
    "            self.mapping[name_col] = (1 - smoothing)*(stats['mean']) + smoothing*prior\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_now = X.copy()\n",
    "        for col in self.cols:\n",
    "            X_now[col] = X_now[col].map(self.mapping[col])\n",
    "            \n",
    "            X_now[col].fillna(np.nanmean(X_now[col]), inplace=True)\n",
    "\n",
    "            if self.randomized and y is not None:\n",
    "                random_state_generator = check_random_state(self.random_state)\n",
    "                X_now[col] = (X_now[col] * random_state_generator.normal(1., self.sigma, X_now[col].shape[0]))\n",
    "\n",
    "        return X_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WoEEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col=None, unknown=None):\n",
    "        self.col = col\n",
    "        self.unknown = unknown\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        col = X[self.col].reset_index(drop=True)\n",
    "        y = y.reset_index(drop=True)\n",
    "        \n",
    "        \n",
    "        data = pd.DataFrame(pd.concat([col, y], axis=1))\n",
    "        name = data.columns[1]\n",
    "        tmp = pd.DataFrame(data.groupby(col)[name].count())[name]\n",
    "        data = pd.DataFrame(data.groupby(col)[name].sum())\n",
    "        data['not_target'] = tmp - data[name]\n",
    "        data['answer'] = np.log((data[name] + 0.5) / (data['not_target'] + 0.5))\n",
    "        self.d = dict(data['answer'])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        col = X[self.col]\n",
    "        answer = np.empty(len(col))\n",
    "        for k, i in enumerate(X.index):\n",
    "            if col[i] in self.d.keys():\n",
    "                answer[k] = self.d[col[i]]\n",
    "            else:\n",
    "                if self.unknown == None:\n",
    "                    raise Exception(\"Unexpected value\")\n",
    "                else:\n",
    "                    answer[k] = self.unknown\n",
    "        return pd.Series(answer, index=col.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X['ACTION']\n",
    "X.drop(columns=['ACTION'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James Stein encoding:\n",
      "0.8103763364273895\n",
      "[0.81555362764622, 0.8180985010925149, 0.8040130331080327, 0.8144851042054078, 0.7997314160847719]\n",
      "\n",
      "Label encoding:\n",
      "0.5749562817265145\n",
      "[0.5570606393210253, 0.5734757195525514, 0.5750767833449648, 0.5913866315902458, 0.577781634823785]\n",
      "\n",
      "Frequency encoding:\n",
      "0.5737751433285356\n",
      "[0.5527798042733864, 0.5792429396835683, 0.580059188562372, 0.592290475222921, 0.5645033089004303]\n",
      "\n",
      "Target encoding, smoothing=0:\n",
      "0.7531736923158906\n",
      "[0.7489537805644831, 0.7692172286985105, 0.7349631079937524, 0.7593989637880316, 0.7533353805346756]\n",
      "\n",
      "Target encoding, smoothing=1:\n",
      "0.7512418140730219\n",
      "[0.7479241017147439, 0.7658059630607085, 0.7339967287107034, 0.7543711850530721, 0.7541110918258811]\n",
      "\n",
      "Target encoding, smoothing=2:\n",
      "0.7461850225529786\n",
      "[0.7459571960311357, 0.7605693748025544, 0.7270030574540243, 0.7533441620296162, 0.7440513224475627]\n",
      "\n",
      "WoE encoding:\n",
      "0.8040961114584521\n",
      "[0.8059055368241637, 0.8080736829976278, 0.797016108779261, 0.8125649315799875, 0.7969202971112208]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    js = JamesSteinEncoder(cols=cols, randomized=False, sigma=0.02)\n",
    "    X_train = js.fit_transform(X_train, y_train)\n",
    "    X_test = js.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"James Stein encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "le = LabelEncoder(cols)\n",
    "x = le.fit_transform(X)\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = x.iloc[train_index].copy(), x.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Label encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "fe = FrequencyEncoder(cols)\n",
    "x = fe.fit_transform(X.copy())\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = x.iloc[train_index].copy(), x.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Frequency encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        te = TargetEncoder(i, smoothing = 0, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=0:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        te = TargetEncoder(i, smoothing = 1, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=1:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        te = TargetEncoder(i, smoothing = 2, unknown=0.2)\n",
    "        X_train[i] = te.fit_transform(X_train, y_train)\n",
    "        X_test[i] = te.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"Target encoding, smoothing=2:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()\n",
    "\n",
    "res = []\n",
    "for train_index, test_index in cv.split(y):\n",
    "    X_train, X_test = X.iloc[train_index].copy(), X.iloc[test_index].copy()\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    for i in cols:\n",
    "        woe = WoEEncoder(i, unknown=-0.7)\n",
    "        X_train[i] = woe.fit_transform(X_train, y_train)\n",
    "        X_test[i] = woe.transform(X_test)\n",
    "    \n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)[:, 1:]\n",
    "    \n",
    "    res.append(roc_auc_score(y_test, pred))\n",
    "print(\"WoE encoding:\")\n",
    "print(np.mean(res))\n",
    "print(res)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
